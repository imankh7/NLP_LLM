{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3KW11y1VfSMe"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qI9u7rFPW5RU"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade datasets fsspec --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRowSLnVXmVn",
    "outputId": "e36285ae-54e1-497b-d6dd-4df5bffedd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/395.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/395.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/247.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "!pip install optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMIIAfJHfvTl"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import disable_caching\n",
    "import fsspec\n",
    "import os\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, DataCollatorWithPadding, AutoTokenizer, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAeLmjPwnC6v",
    "outputId": "d15f5acb-14f7-4d19-ada4-df81bb2589a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.3.0\n"
     ]
    }
   ],
   "source": [
    "disable_caching()\n",
    "print(fsspec.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "6fa1071f7fa741cdae8e2de595cdd9a4",
      "6bc1a01082624596b317ebbede1065c0",
      "965837005d2a48568899e347b7a6bf40",
      "d336a50d67dd4ee995d030e31fa3928e",
      "bcde9b8f70204e6fb01b569034c91afa",
      "b023a2bd8e9a45b6af84345a178a00e3",
      "12591317ffe6499f837ac30a6bbeb166",
      "0f245cd0a66840e0be138e67039fb036",
      "f1a021af04a840648d217a75db79b5a3",
      "8029e9d96e6e485aa649d00cc5756da1",
      "3953db0274534b2f9e7929d1c9dc1d08",
      "3630ed8961f448e2922a7f42e320fc97",
      "a1b4a896dcab41719cd40c3741d5d8b3",
      "f129acd101324d39b42a6ca236f5eec1",
      "ee625dd612b04067b6f634d6e1e346d8",
      "a5dbb47e25a5471a8b0e5770564d5bba",
      "ce64851d23584340a1f7ddfda88e7c31",
      "39793523289e45fc8162de5191f095f6",
      "b4fd88b4efeb4f5686db82418ebb15af",
      "ae8bbb9d1f39409d89713153c48f7bf8",
      "e02294895b7648f8abfe9e9dfbe50ed4",
      "fac1a6f923b541598ffbbb3fe8759e4a",
      "b30c5467ddcb403bb9b0ebebce5526a2",
      "902f51f53e7a4e4bab2cc4133d48449c",
      "908095dea4ac442b8fa4056a3d42bc18",
      "29e4b97f4bf94054ac64c0a921424fd5",
      "e505bf7764364ec1b516599b97907b6a",
      "a5810fbe38f6449bbf6e48d808fbc957",
      "2d01d19a36f2437297f0bee9de9b8086",
      "0e805c59aaec4715a7eed921b7ba3982",
      "b8946c5e78a4456eb33854b9bbd302b1",
      "b63051c10536417bb5b06e26d103e01d",
      "84e6132e3e114e24b7cf2e4dc1334c7a",
      "6eb7b932c0554b40b2268e54d13c1e2e",
      "50ad167df0074566a602a9eb053b6207",
      "25e2b8cbfdba4727aeb706244ab83141",
      "e78c35bad93e4e879256d36d0c2cd21c",
      "7b1b73a1934b4fa98e55377421ce27d9",
      "5f7dd342cd764c7bbd07dac16c08707a",
      "495d103c75224c6d9c14a7f6aef6e42a",
      "5657efeb25b4425aac4032f43dc7f5ee",
      "b5042ba305aa4773a834fcd454b24e07",
      "19067a36bbbb4f418e3ffa7e7d1f2028",
      "49f95f89239a4165b230f888a98debdc",
      "c1486043263d4d96ac9262201b27bed5",
      "9adec036c3754f6aba8b78075fd0450a",
      "dd9aa8517f764a11a055bdfda28104f5",
      "a4964f015d054659acac44a229617fda",
      "a6f369c8c56c436691d5870a0f4664a2",
      "eed2bf0b3d00418bb86e39a7920e3881",
      "04ef26fd3b7c4ac0ab1bb1531ad09555",
      "9626242e2c2947fcbc9f53248f85e9bc",
      "46c5f463d3de41bb8f3696a9ec594fb0",
      "97d112fcb28a4a1289ab471599fa5450",
      "7875c14463674eb7acfb67ead05b6103",
      "c5fdb466c2eb4cd58988cc7c90062817",
      "9937de3433db4519abd26ab8a36f1d06",
      "52a23e8822e548ebacea2c2646ae4432",
      "4a2927aa7522403da6a05f5edaf22255",
      "8c4115b44d5b435f8fa76cb253fa1b09",
      "cb0cdcb926d34f09a172fa97ba9d5483",
      "f35a2d2a596243c980dac915caf86414",
      "2d021543108d4e6d97c09733a31765f7",
      "8b6c73ea8a2d4deda78d873bc1c40659",
      "c8d08e8842e4423c99b2bebc82be131a",
      "211b8582cc9146c28b9d51772ba2b3c0",
      "5f5c28dbf5d4442b94d070822596ebb2",
      "b6e4bababba5475b936d33eff8f5e322",
      "7c7832ed62ce452297eabe1e89dffe97",
      "7eb45e3ec1764d40bc65e5dbba8b700d",
      "8e63b818c9d4450ea7fd2fae1d2f37c3",
      "d987bcb407564585abfa72220e26f2aa",
      "c31909e44f234f598ecb7dd8866513bb",
      "0a8139c0c7784008a1f4ef5545ff6f4c",
      "ec47824ab37b4ef5a4cc67113811d359",
      "035af523a1fa44668f0823b53850220f",
      "6750108c72494bdc9d46a7ca358f343d"
     ]
    },
    "id": "SQ1MMj59nlAo",
    "outputId": "60f27fa5-f495-4c36-c887-9772dd2408f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa1071f7fa741cdae8e2de595cdd9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3630ed8961f448e2922a7f42e320fc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30c5467ddcb403bb9b0ebebce5526a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb7b932c0554b40b2268e54d13c1e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1486043263d4d96ac9262201b27bed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fdb466c2eb4cd58988cc7c90062817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5c28dbf5d4442b94d070822596ebb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_dataset= load_dataset(\"glue\",\"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Q-_qNnnnvkq",
    "outputId": "fd30d4f5-1721-48ed-d1d9-352b9ce166eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59ypADDqod3P",
    "outputId": "15c0e366-5ed4-4c14-a0e7-5a1a089d6ede"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       "  \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\",\n",
       "  'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .'],\n",
       " 'sentence2': ['Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       "  \"Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .\",\n",
       "  \"On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .\"],\n",
       " 'label': [1, 0, 1],\n",
       " 'idx': [0, 1, 2]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset[\"train\"][0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "877566fff6b3465099159c199ffe2650",
      "7cec0309509341b7b037e320e706c66f",
      "9f6754ac97214a958d7143a433b3d8e1",
      "cfcd3ec03b8c4fde884128c4ccc75ca0",
      "f04fd8513a3d422abb0d20adbbc70884",
      "182aac4cc1e54147b4037a54b333e4be",
      "a1640899078a4d69bf7132610d575c0d",
      "8560a1f731d7476cbfceea92c75ffeff",
      "d3b68270f6f74baeb01f571a5d41b30d",
      "9b084532b89649acae0be63732e54400",
      "1e0696f60bfa4edea4697eda66801c25",
      "7c252debd13d4e34b272daef2a487524",
      "21c5191d767646098ec87ffb94f9a842",
      "ca467877fc6f437b958c3fee52dad20b",
      "a3647d8c59664d999075844994006ef5",
      "3560386946cd4a5187c4ef8db6ec1f09",
      "9c5b41fa53e64984a9af104a18b08d0c",
      "7d949d68e7504860b5ad05723be1d889",
      "5d4e7f426a434f8b90f83da93462e72c",
      "3167e00bdb4d4a8394d1d4e525eda0fb",
      "121f745416a2441c83d4864c547cc916",
      "76cf64044a104454bb05b7a2763111f9",
      "d8f7f2ee49504eebbff0261f897f6ffb",
      "ad39a5d6498f4ac1a3ed30b2443a38d9",
      "df044aeca3b549e1a3a59012f3848b3c",
      "f18e0220c58d4925a3feb614f8c8f58a",
      "e4f057357f0c4162847935a7b2a50da0",
      "0d08f2c1a7f34f23a14608a45e24c6a4",
      "36a60123fd3540ecbcc08b9cd014dc03",
      "b256beb2c1af41b6bcce73941b6f1bbc",
      "4f8ff9b16f744059a8f3b6bed2e6ead7",
      "be76cea8e9564559aafb20c7fb7c2124",
      "847b4396282d45afac097d1da021b0dd",
      "c024aad02c0e43dabcfd956648c9e391",
      "bc87db7fa5f049beba9f3d58deabc0a7",
      "847a78720fb84bfa821bfd89dfad1e4b",
      "001724ef1c5447ed9886e8f5f395d14a",
      "9a69f9c088d34f9bb235c6e1cb3e8647",
      "db6560e7c70f44a69913a44376233db4",
      "32b65653a62544528b8201544999c8d9",
      "e9c1bf5eba01441fb202d8c7a61263db",
      "92ce55cf7efa4a91adaeccd57b668a2a",
      "87360820bcc44b7d84b828ea195c29f1",
      "8856697011b74486bfe90c385ed7ed1f"
     ]
    },
    "id": "hvy809Aco2Tw",
    "outputId": "299f567e-ef65-4543-e620-5d7a9e690a4f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877566fff6b3465099159c199ffe2650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c252debd13d4e34b272daef2a487524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f7f2ee49504eebbff0261f897f6ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c024aad02c0e43dabcfd956648c9e391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBt4WVadqI1c"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "a7e983ef1e9e4b89a8d20b3f9adcbfd6",
      "fb5597c6c24443618d02f57fb0a97c54",
      "347bde1ab8f448e0afecb4f8360253e6",
      "bea3f7d1bb8c4fdbb347b3c80be65e53",
      "e25762f465f14830a3d717d585a896b6",
      "89cab0b3fb0f496fab619328f2ae4d13",
      "f00fa38769334774b369042e9c4d98cf",
      "524a22605dd24f09985df825909b82e9",
      "c2dc52b2dd204e8a9de085725acd87b9",
      "a59ab3c3edc14f2ba1544eb2aba9aea3",
      "e528147999bf49d4a23eb5c898eb75ca",
      "726439b56d8445e199a6b4ef1b09b7ef",
      "5db04e40624c4dbdb2a9b0fef6f2f843",
      "1494723c0cdf476c98a4a285f94a0233",
      "f436b4378f57444290e6b4663f0eebef",
      "5c9aaa98896942cf8134eeba53a6c336",
      "4540d6a60dd942cbb6a56f5f04cf99be",
      "cc1832abc50f47b5a257448dc9222491",
      "f485d1257fc74cffbb2429b7112adc75",
      "da93dd187cab4f3d895d352460eb66b5",
      "bef3fcc465c14423ba6635a39ea2a300",
      "df05e3bedcf446fcb93e6d6a4754ec84",
      "abe4e8b55e1e4fb6b9ab5fec48c2fd4a",
      "c147f57e49ae4ecfbea75a571221ab5b",
      "20ea23846579488bb84754130e1b9787",
      "80dd455ab91e4314b2f64f261bb6fbd0",
      "1b20492697484981a6d012312571ae81",
      "0eb3933700224423961eaf68dbf04ce2",
      "f3b3dedda49e44728e8e99d35304a4ef",
      "8f8f17a9fe2e4c558ed5ad44c208768d",
      "7648fb0097024ef78e87c9794706bbbf",
      "2aa5276a5405467e9afc3dcef118a37f",
      "bacccec062a54514bada00d860d17083"
     ]
    },
    "id": "DUvuLX9TrWLJ",
    "outputId": "032272fa-7952-4c60-d523-5d48f96f0434"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e983ef1e9e4b89a8d20b3f9adcbfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726439b56d8445e199a6b4ef1b09b7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe4e8b55e1e4fb6b9ab5fec48c2fd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dt= raw_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCgfUUUNHcyG"
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161,
     "referenced_widgets": [
      "e880063861ed450486d17f3ab8358f9a",
      "dff6f80baf904c97bcc4c42356c14744",
      "e482d2fbd1a341e48756fa51943d1422",
      "516003bb06a14475b6510cf1905774f2",
      "e6c2fda858fb4dff8591eb8156bb2171",
      "181ec39d04ae4366bbfd6aa072dbf8bd",
      "aff855ce3fe94dfb8b3a93d8ec06a094",
      "66dcb6c7683c477082873e6ac93ecb44",
      "ebea261ced7a450fb49c58f55d3b8b0e",
      "99e4f30f93144285a672e075a6f49611",
      "10edc3c30d6f48439a917b6784c7b4ee"
     ]
    },
    "id": "ztDQSTl9uRg0",
    "outputId": "5469318c-f632-4059-efe5-4656eb1f3fe4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e880063861ed450486d17f3ab8358f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipython-input-2474377437.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "data_collator= DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test-trainer\",\n",
    "    num_train_epochs=3\n",
    "   )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dt[\"train\"],\n",
    "    eval_dataset=tokenized_dt['validation'],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "id": "VooHMCSyrZDU",
    "outputId": "01793549-762c-49f1-f3b0-64726391b2f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 01:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.498400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3295960990778328, metrics={'train_runtime': 119.0621, 'train_samples_per_second': 92.422, 'train_steps_per_second': 11.565, 'total_flos': 203961502572816.0, 'train_loss': 0.3295960990778328, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "1U1jPZ0KvSUY",
    "outputId": "7f16e2ea-a518-4d4b-dae7-c0a1d626dba8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6903791427612305,\n",
       " 'eval_runtime': 1.1451,\n",
       " 'eval_samples_per_second': 356.313,\n",
       " 'eval_steps_per_second': 44.539,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QiLHXW_fzOc9",
    "outputId": "c2b0ac0e-99f1-4479-9f66-77f32c0eb2cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(408, 2) (408,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_dt[\"validation\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gg00PpvY0xuS",
    "outputId": "75264a95-b330-4796-e09c-e042585c2012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 1 0\n",
      " 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0\n",
      " 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "preds=np.argmax(predictions.predictions,axis=-1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_z6g-Bmu9nO3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits = eval_preds.predictions\n",
    "    preds = np.argmax(logits, axis=-1)  # Convert logits to predicted class indices\n",
    "    labels = eval_preds.label_ids\n",
    "\n",
    "    metric1 = accuracy_score(labels, preds)\n",
    "    metric2 = precision_score(labels, preds)\n",
    "    metric3 = recall_score(labels, preds)\n",
    "    metric4 = f1_score(labels, preds)\n",
    "    return {\"accuracy\": metric1, \"precision\": metric2, \"recall\": metric3, \"f1\": metric4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsvR0A5x-IBb",
    "outputId": "84081fba-a115-418c-fd0c-37fa603f04c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-4074095883.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_2 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer_2 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dt[\"train\"],\n",
    "    eval_dataset=tokenized_dt['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "A-bYlJT6-Yrq",
    "outputId": "020cf518-51ad-422f-cf1b-50c86cd32282"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6903791427612305,\n",
       " 'eval_model_preparation_time': 0.0015,\n",
       " 'eval_accuracy': 0.8455882352941176,\n",
       " 'eval_precision': 0.839622641509434,\n",
       " 'eval_recall': 0.956989247311828,\n",
       " 'eval_f1': 0.8944723618090452,\n",
       " 'eval_runtime': 1.0158,\n",
       " 'eval_samples_per_second': 401.662,\n",
       " 'eval_steps_per_second': 50.208}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_2.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bi67RH-G_oMu"
   },
   "outputs": [],
   "source": [
    "# Optuna for model\n",
    "def model_init(trial):\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\",\n",
    "        num_labels=2,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0Yi4VEPAMm5"
   },
   "outputs": [],
   "source": [
    "# for each hyperparameter\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 5),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKzTmYNMA0EA",
    "outputId": "3fc8775a-816d-44ff-c86e-781c490ce5b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer_3 = Trainer(\n",
    "    model_init= model_init,\n",
    "    args=training_args,\n",
    "    train_dataset= tokenized_dt[\"train\"],\n",
    "    eval_dataset= tokenized_dt[\"validation\"],\n",
    "    data_collator= data_collator,\n",
    "    compute_metrics= compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "gN9Ao-c8BRrJ",
    "outputId": "b60f06aa-8f40-4a19-94f6-6e222fdbfbe0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "[I 2025-08-07 15:03:43,857] A new study created in memory with name: no-name-a0933a98-ba2a-4ffc-bf8a-c268ae380b2f\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 01:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.406300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='306' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 10:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:05:34,997] Trial 0 finished with value: 0.8934010152284264 and parameters: {'learning_rate': 3.100852453421338e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3}. Best is trial 0 with value: 0.8934010152284264.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/345 01:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:07:02,102] Trial 1 finished with value: 0.8946459412780656 and parameters: {'learning_rate': 2.3930063747492778e-05, 'per_device_train_batch_size': 32, 'num_train_epochs': 3}. Best is trial 1 with value: 0.8946459412780656.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 01:46, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:08:51,593] Trial 2 finished with value: 0.8904109589041096 and parameters: {'learning_rate': 3.09958742464868e-05, 'per_device_train_batch_size': 32, 'num_train_epochs': 4}. Best is trial 1 with value: 0.8946459412780656.\n"
     ]
    }
   ],
   "source": [
    "best_run= trainer_3.hyperparameter_search(\n",
    "    direction=\"maximize\",\n",
    "    n_trials=3,\n",
    "    hp_space=hp_space,\n",
    "    compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fX3wMYKoGRFZ",
    "outputId": "fea78e7e-5b1f-4d9a-ea92-0a6dfee170fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_arg_final = TrainingArguments(\n",
    "    output_dir=\"test-trainer\",\n",
    "    num_train_epochs=best_run.hyperparameters[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=best_run.hyperparameters[\"per_device_train_batch_size\"],\n",
    "    learning_rate=best_run.hyperparameters[\"learning_rate\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-pBQtf7GdAC"
   },
   "outputs": [],
   "source": [
    "trainer_4 = Trainer(\n",
    "    model=model,\n",
    "    args=training_arg_final,\n",
    "    train_dataset=tokenized_dt[\"train\"],\n",
    "    data_collator = DataCollatorWithPadding(tokenizer),\n",
    "    eval_dataset=tokenized_dt[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "fYMoIViPHeuj",
    "outputId": "03e5452f-96e8-4aff-80e1-1c0d51db60ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/345 01:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=345, training_loss=0.05483538862587749, metrics={'train_runtime': 88.7024, 'train_samples_per_second': 124.055, 'train_steps_per_second': 3.889, 'total_flos': 226895955866688.0, 'train_loss': 0.05483538862587749, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_4.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "vWvZZzwQHgtw",
    "outputId": "5b195f02-e3e1-429b-d056-c079bb20a916"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8989779949188232,\n",
       " 'eval_model_preparation_time': 0.0023,\n",
       " 'eval_accuracy': 0.8284313725490197,\n",
       " 'eval_precision': 0.8255451713395638,\n",
       " 'eval_recall': 0.9498207885304659,\n",
       " 'eval_f1': 0.8833333333333333,\n",
       " 'eval_runtime': 0.9868,\n",
       " 'eval_samples_per_second': 413.443,\n",
       " 'eval_steps_per_second': 51.68}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showed overfitting\n",
    "trainer_4.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfQdkT_UITkq"
   },
   "outputs": [],
   "source": [
    "# We try to solve overfitting by earlystop and L2\n",
    "\n",
    "def hp_space_2(trial):\n",
    "    return {\n",
    "      \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "      \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8,16,32]),\n",
    "      \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2,5),\n",
    "      \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwHlSpkSKKfs",
    "outputId": "f4d6249d-4c0c-47ca-8a1e-9ea500193305"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer_hp2 = Trainer(\n",
    "  model_init     = model_init,\n",
    "  args           = training_args,\n",
    "  train_dataset  = tokenized_dt[\"train\"],\n",
    "  eval_dataset   = tokenized_dt[\"validation\"],\n",
    "  data_collator  = DataCollatorWithPadding(tokenizer),\n",
    "  compute_metrics= compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 724
    },
    "id": "cU1nwmoPKdpo",
    "outputId": "2827e746-e1cb-4dfe-f265-8d5e64939181"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "[I 2025-08-07 15:34:04,779] A new study created in memory with name: no-name-b5e3bda9-be3b-43d3-bdc2-158145cd5d75\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2295' max='2295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2295/2295 04:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.503900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.115000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='153' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 06:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:38:34,253] Trial 0 finished with value: 0.8949152542372881 and parameters: {'learning_rate': 2.323906804171938e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.1806779271813365}. Best is trial 0 with value: 0.8949152542372881.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 01:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.427000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:40:35,773] Trial 1 finished with value: 0.8957264957264958 and parameters: {'learning_rate': 2.3092053238158384e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.21632510271940797}. Best is trial 1 with value: 0.8957264957264958.\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2295' max='2295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2295/2295 04:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.077300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-07 15:44:53,968] Trial 2 finished with value: 0.8941176470588236 and parameters: {'learning_rate': 3.530561343413613e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.2438719105641908}. Best is trial 1 with value: 0.8957264957264958.\n"
     ]
    }
   ],
   "source": [
    "best_run2 = trainer_hp2.hyperparameter_search(\n",
    "  direction=\"maximize\",\n",
    "  n_trials=3,\n",
    "  hp_space=hp_space_2,\n",
    "  compute_objective=lambda metrics: metrics[\"eval_f1\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8moBfPiKyPU",
    "outputId": "3655f69d-cdb8-40de-83e8-0ca94d952904"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "best_args =TrainingArguments(\n",
    "  output_dir=\"test-trainer\",\n",
    "  eval_strategy=\"epoch\",\n",
    "  save_strategy=\"epoch\",\n",
    "  learning_rate=best_run2.hyperparameters[\"learning_rate\"],\n",
    "  per_device_train_batch_size=best_run2.hyperparameters[\"per_device_train_batch_size\"],\n",
    "  num_train_epochs=best_run2.hyperparameters[\"num_train_epochs\"],\n",
    "  load_best_model_at_end=True,\n",
    "  metric_for_best_model=\"eval_f1\",\n",
    "  greater_is_better=True,\n",
    "  weight_decay=best_run2.hyperparameters[\"weight_decay\"],\n",
    "  warmup_ratio=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nc1xSQ2iLUVS",
    "outputId": "de9f4e72-7480-4a2c-8c9b-1e59d642a9b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "final_trainer = Trainer(\n",
    "\n",
    "  model_init     = model_init,\n",
    "  args           = best_args,\n",
    "  train_dataset  = tokenized_dt[\"train\"],\n",
    "  eval_dataset   = tokenized_dt[\"validation\"],\n",
    "  data_collator  = DataCollatorWithPadding(tokenizer),\n",
    "  compute_metrics= compute_metrics,\n",
    "  callbacks      = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "KK7htEMfNieD",
    "outputId": "d1bf42cc-6485-4eae-a31e-ef70d5bd2af9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='690' max='690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [690/690 02:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.385931</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.872792</td>\n",
       "      <td>0.885305</td>\n",
       "      <td>0.879004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.338383</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.902564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.384427</td>\n",
       "      <td>0.850490</td>\n",
       "      <td>0.853896</td>\n",
       "      <td>0.942652</td>\n",
       "      <td>0.896082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=690, training_loss=0.37941413547681724, metrics={'train_runtime': 155.9857, 'train_samples_per_second': 70.545, 'train_steps_per_second': 4.423, 'total_flos': 215773868887344.0, 'train_loss': 0.37941413547681724, 'epoch': 3.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "id": "RxyoXuV1Nl5i",
    "outputId": "0fef193e-e386-4005-fab0-f99f3e082e49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39531487226486206, 'eval_accuracy': 0.831304347826087, 'eval_precision': 0.8548922056384743, 'eval_recall': 0.8988666085440279, 'eval_f1': 0.8763280917977051, 'eval_runtime': 4.5511, 'eval_samples_per_second': 379.033, 'eval_steps_per_second': 47.462, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# epoch 2 has the best weights, we saved best model at the end = true\n",
    "testing = final_trainer.evaluate(tokenized_dt[\"test\"])\n",
    "print(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AJfnAx84PTt0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
