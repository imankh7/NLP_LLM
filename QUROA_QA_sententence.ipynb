{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc92Q8tfykkI",
    "outputId": "e41b43cd-dc3f-4502-9b99-480874273b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers transformers chromadb langchain datasets streamlit --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_rAkeU-8eSi",
    "outputId": "b9663270-9031-46f4-aa08-1ccb55d750d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BVUcqZ35y2zr"
   },
   "outputs": [],
   "source": [
    "import sentence_transformers, transformers, chromadb, langchain\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from chromadb import Client, utils\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import  pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353,
     "referenced_widgets": [
      "58e3e637f31f43a8a4c0b81aa16940a7",
      "90a72e4f53cf47e1af0e0c5904df86cc",
      "c673bfcd800f4cda96df4e44a2de265d",
      "a41516f3b975404b9b62b5f724d89852",
      "b0baf0cc8aaf49e0983612ec2aaa28c8",
      "2ab66220b7024bca86de75d11da5bf66",
      "1ec2d9652dc64968a214ec529f3e7a72",
      "861d15b82b3d416f8968362af81e3f1d",
      "595706362057490aa040763a6d65a0b7",
      "d621b93332754bab9a8a311c1acc0d17",
      "d2249ec82586488eb6705edd2e540266",
      "8a30b16591674b2c98baca40b0d68143",
      "61a254dff06d4dd9a697a46dc50f2fa5",
      "82d0b995ac3a4c798019347058758409",
      "406c89e4dbd34d589ee6fa1f2742dcec",
      "1df7873e97ee4fba88ba50b2845a88f0",
      "8f34ab29886f4793b91eaee780a25406",
      "bd3e10a573fe4fc19d992e2dfeba6d36",
      "ecc2781de0224dc9959089718fdb6959",
      "13cb30c0aac843e0a29ffa16d0d2d29d",
      "82f178a05c3a474796f44d1e84bcbe87",
      "700e70965fab4e3e8eab4d8ce8451d22",
      "87a153db0b7d48ecb2c550a1eaeaa4c6",
      "d59a9251dbbf4823b3f5abab77352545",
      "580d04d245494a3eb2382a8f057dba5b",
      "2ca04a1530ba4516b12cfc92a1d4370d",
      "4b0019a951034117a3189b04c617b5c4",
      "5f66cec25ffc4e5b9756d60a55f41dab",
      "0723519e1b824f0fadaf075476012111",
      "1bee356dd8524e2f8d4ea2e4d3ead23d",
      "ad5a7a11e9b04e798d9dd7132ecf9a15",
      "ffd5fcc8f5e042748a6eedd82fa1acb2",
      "b968816a23dd44fe87306dfd8d51cceb"
     ]
    },
    "id": "aTqjv2ODzW5h",
    "outputId": "44629599-ce49-4195-c8dc-f7200d920d85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e3e637f31f43a8a4c0b81aa16940a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/485 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a30b16591674b2c98baca40b0d68143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quora-QuAD.jsonl:   0%|          | 0.00/60.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a153db0b7d48ecb2c550a1eaeaa4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/56402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 56402\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = load_dataset(\"toughdata/quora-question-answer-dataset\")\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PSMPvV4zgkd",
    "outputId": "750870ec-b5a1-4025-888a-a3123780977a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I buy IKEA or IKEA-like furniture in India?',\n",
       " 'answer': \"Ikea is known for its low prices, so it's common to understand if we pay less then can we get the [LINKED_TEXT: best quality] [URL: http://www.thehomedekor.in/], the answer is straight away no. It's not about India they have the same quality level in the whole world, but in developed countries soild wood furniture option is much expensive whereas in India we get soild furniture at best price because its made in India and India is one of the biggest exporters of solid wood furniture in the world. So for us its better to buy soild wood furniture instead of buying ikeas imported Chinese furniture.\\n [LINKED_TEXT: To buy modern design like Ikea] [URL: http://www.thehomedekor.in/], The Home Dekor is the best option to buy modern ikea designs in solid wood\\n\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['train'][900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "52c944b799014b4aa1e31807b3e9223e",
      "b4c5127992454ed7b196c660469c0671",
      "53153dc645474be1be0fa940cfba66de",
      "57cfd376bfab448bb0791ba2b9a24612",
      "50ad9c4248d948cda8fc22d2da39fe57",
      "8c1b018cef4143029e3921035b0f60cd",
      "202b15a4db30488db6d370e3785f61cc",
      "f6fe57c1739f4a6db4057eef45c407ef",
      "66ab0b5c588c45eb9c13fc4997e3e24a",
      "a18269702b3b452693c7e252347813b9",
      "5fa6aaaea80d495e9a301dbcfbb207be"
     ]
    },
    "id": "MsNHIPrIzqP5",
    "outputId": "70aafab1-c187-47f6-e498-e8347f09b49d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c944b799014b4aa1e31807b3e9223e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56402 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Why whenever I get in the shower my girlfriend want to join?', 'answer': 'Isn’t it awful? You would swear that there wasn’t enough hot water to go around!'}\n"
     ]
    }
   ],
   "source": [
    "# need to clean data\n",
    "def clean_text(text: str) -> str:\n",
    "    # a) remove [LINKED_TEXT: ...] and [URL: ...]\n",
    "    text = re.sub(r'\\[LINKED_TEXT:.*?\\]', '', text)\n",
    "    text = re.sub(r'\\[URL:.*?\\]', '', text)\n",
    "    # b) collapse (spaces, newlines, tabs) into one space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # c) strip leading/trailing spaces\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess(example):\n",
    "    example['question'] = clean_text(example['question'])\n",
    "    example['answer']   = clean_text(example['answer'])\n",
    "    return example\n",
    "\n",
    "cleaned_dt = dt['train'].map(preprocess)\n",
    "print(cleaned_dt[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvnhXCTH0DVO",
    "outputId": "8e0227fe-7107-4fad-bf85-91f92fcd54e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I buy IKEA or IKEA-like furniture in India?',\n",
       " 'answer': \"Ikea is known for its low prices, so it's common to understand if we pay less then can we get the , the answer is straight away no. It's not about India they have the same quality level in the whole world, but in developed countries soild wood furniture option is much expensive whereas in India we get soild furniture at best price because its made in India and India is one of the biggest exporters of solid wood furniture in the world. So for us its better to buy soild wood furniture instead of buying ikeas imported Chinese furniture. , The Home Dekor is the best option to buy modern ikea designs in solid wood\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dt[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "S7HtTtOM3PnU",
    "outputId": "329823ba-72d3-408f-96b5-4216687856ad"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Why whenever I get in the shower my girlfriend want to join? Isn’t it awful? You would swear that there wasn’t enough hot water to go around!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_txt=[]\n",
    "for example in cleaned_dt:\n",
    "    qa_string=example['question'] + \" \" + example['answer']\n",
    "    QA_txt.append(qa_string)\n",
    "\n",
    "QA_txt[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444,
     "referenced_widgets": [
      "4cf510f5d82c4860bdc189b5c1f7ee84",
      "36a2f442d2cf4727bee6677e9723d12c",
      "cb899b4cf5bc4e759c4e67af609013e9",
      "2dd5aa39799f4df89798a44dfef6a4e1",
      "ccecac0e9a234074a1493d08abd1670b",
      "7f83627996b14562993551d7f38e3fe1",
      "7c4c7438e7794b0993f52637a8178fb5",
      "99074337a95e45a8a3dc1a1e215945eb",
      "ce15a4281ceb4993b534b57e3effe109",
      "acb9dc1ba58149528f8ed65d68c62419",
      "0d494d4282984c4d949f92c17f12869b",
      "e925a361ad9143cc9a01bef2a5229e89",
      "6ec0cb151ea94e18909332cc231d1551",
      "e1c80650f2c6450c9b3a22ec0d606138",
      "da8f48ec3ee24c95bf462109205a756e",
      "f6b167567eb84ae6947bde6d78a58a7c",
      "2b8686694d5a429d8d50797a61c37ffc",
      "c49f425f49874f328c9158d3b98e59ae",
      "315b7cf896324bdea6d5f3dc10fa5268",
      "1bb844ff969d4a72a911a53fc576b714",
      "cd2682504a454ebfbb73e53ddaf2b6b3",
      "d1bf8b8da02d4b5a82f1108d9f61e21a",
      "a4978556873e4790b96349a22f4f3b25",
      "4caa716cdf984609a882f3f48282e87d",
      "6eb5b2d7b64b47ce9292cf445b131036",
      "f49a12b35e064333ba8f4dc6c814f3ee",
      "849121f16f3e42e786460c4f09c4d121",
      "bfea544d200a4933a130d05f1f29dbc6",
      "892aaa52f1684c528710d46c8b2565ec",
      "4f24f4a5ea154c8eb97ec55203c4013e",
      "79e65d36c9734d58bc4a58ff3acc3b6e",
      "32870d4ea69d4e1598cd153b6d3d4d32",
      "08cf16414844411b91a1be88d1f14172",
      "158e605a0c834d1c9b22339dd6029bb2",
      "b4ff839a21634109a0d5c8a00c6f96b4",
      "afbe2b47d1e84b4da524f711560f3cff",
      "e211013fe4594acbbe8c439ce4dffd2a",
      "fa212d3c1b064138818c429ff3754c89",
      "db7bd84c2c514ebeaaad67d3e6c7a01f",
      "86d18e6339a54a1f9026f1702d02cd26",
      "5141ce026e224605844bd7689431b5ab",
      "11dd78f956984f44ad436d99c5cef41a",
      "87328676915a450c901d6d04fc97cf50",
      "b8b20b0c68d247a7a8949a97257c0c46",
      "e2fa51ddf70848c4a1010b738d4f7ead",
      "ce3e3d0d770e484fb15ecc2e4675f16c",
      "e318ea9f8a464feab394929bb843c78a",
      "15b2ab2cb3284d818648fad0542b8d80",
      "47741539f7f7467a96dfdc6cbf10466d",
      "7b0b5153b06143c9bf0bccabb97c6b50",
      "7108f0a53f2449a9a56f38c6bf6de7b4",
      "0d800959d2904b12873c3b1efccc56e5",
      "f3ef90e077bd4aa8b942cd2eeefaaeb0",
      "f569d2e21a9147bd92fd8e81581fad2f",
      "bbfb631d59c749f5b3ba0dd4ca82dbbd",
      "a1ac3f3da1f94a21a4546c0fcb8592e7",
      "931de411b5e5474db011957013d01e85",
      "6310f63ea8f84c9c846a930c1d285fd2",
      "3683231256234eb68813a9474bfb5abb",
      "74e9f777bd9c4c81982d13d316e1f7da",
      "60a4bcdecec142f8b8ed397a2882202e",
      "d79a6429553343c0933475ff7b53c14b",
      "bc34da1a6a104f1485f38a17b6f44ac1",
      "afc103cd2cdd4877ac247d1e0379984f",
      "4c51ea132f47441cbe8d9a7a857f6e0b",
      "703e24c09d654b16bac390d2a5e33c32",
      "31d1feb1ec9b481ca249172120b77b82",
      "fb784a099aea452a950dc62a7816dbf8",
      "66de07435da441b4958f453c6dcd7cc0",
      "73e71c2d6c2b4b5a9abcb3ab60864dce",
      "d1478bafcb4043ef8a965f66718178e8",
      "552d29f5f8ed4248abdada3c2f36d174",
      "0996341786f5467c9e7f6f01b6cee645",
      "1206d940a4004bbc9084d99acfade529",
      "d3912f11e8994f74a0c62b2836a37863",
      "a8a02d11d9914896b3bb0019440bac9a",
      "c65dbea5ce114cb599ca0307bb7e3628",
      "f0572a3a79ec4a9e9a8c090fbb796a2c",
      "16702b8b42bd492d8102c1a9e7d94ee7",
      "586738bbca4d4609801d417091a23ed2",
      "a9d7eaa65d9346608a665ad1e89b7d2b",
      "95d17af7cc65429fb103b3a2be3a8f99",
      "3a72e9a5c34c41f0926b6e17555903a5",
      "8b42328505954035b23ee68b21e790f4",
      "6e932effb0ae4864ad4fe301cb830969",
      "ad0126b5ba994ab491856a8972d48f65",
      "601873a70f5040d69b72f43d1e2f37f7",
      "dff4158e8938441281fbd7707f325b47",
      "51762617b3e54070b900e38ec95b7036",
      "89ae28910b8040bfa6478c762d3389aa",
      "d342619777f04f7c9a33853befa026ff",
      "e7c994e0bd98495aa30df1c572bc4dbe",
      "9387fed8f08a41069698b6b90ed11557",
      "be41f6f0e9054c039d3980e7835d55fd",
      "ce2283d89ce24af1bf21822d9f92f28e",
      "52f88d97622d40d1ab2df122943aec25",
      "0c9b60c5dd34466eb39fe5f21910c9d3",
      "2567f706f6794876a60a0737fd314e5c",
      "ffdc5e9f896348699f68b986b630211c",
      "0c233c8c08294b6f805d68c31b9e6207",
      "89eec075e3b0490d821a858ca40a1e32",
      "20bf83ca610042a1a2fc94b81595801a",
      "a95e95f8162d42cdbe380e0cdcf31093",
      "9c9cf956616c4eeeb10522fd34156dd0",
      "5eba881fcff946798b922fd8a3b9d60c",
      "89526d4d28b245108f01e5ad8170951d",
      "e6e0a33cdd1d4392931d201a9c26f172",
      "f2259335fc0647d0b6b1c2765023c7b4",
      "59f287a464be4167b1719272c77453c1",
      "885a613743024c0bb2023b1fd7c08918",
      "7bd3048307ad41e3a8597464d63a99c0",
      "0d2c7b69c7be44fa8f283cfb608f0bf1",
      "ef065057f7844da0ac6158e46fdb5e45",
      "b4cd2f72887f44d2ba36e79f9b36aaa2",
      "e5034f69c5734009a54bfa7ac6f266c1",
      "412ec1f1c20e4abb89167b6ed8d85127",
      "9c5c9b72c59c46e58e1ac43dc05ccbee",
      "05f19f7331224350b7b72a8c2998b4d2",
      "ff05f5ae66744ce4aa8bb93f11d9053e",
      "01a9274b85ce4195b9db578a37d3c4aa",
      "af962d01570b40628be8a27039301674"
     ]
    },
    "id": "bBYr7l2n4y71",
    "outputId": "f120c2cd-9bd0-403e-fbb8-519e67d2b89b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf510f5d82c4860bdc189b5c1f7ee84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e925a361ad9143cc9a01bef2a5229e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4978556873e4790b96349a22f4f3b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158e605a0c834d1c9b22339dd6029bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fa51ddf70848c4a1010b738d4f7ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ac3f3da1f94a21a4546c0fcb8592e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d1feb1ec9b481ca249172120b77b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0572a3a79ec4a9e9a8c090fbb796a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51762617b3e54070b900e38ec95b7036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c233c8c08294b6f805d68c31b9e6207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd3048307ad41e3a8597464d63a99c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sentence_transformers.SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "single_vector = model.encode(QA_txt[0])\n",
    "single_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "a202b38f360949528369d2045dee1903",
      "70dcad14b48c48e0a34e6d7fc2b26023",
      "a4f7f6354e87434bbdcec4655edcac9d",
      "5ddd95fc384c47bab5751d094f1d53da",
      "9ed365dfc2f245b1a796c1c11a48bfb3",
      "2f9943ce02394d4997180d5ad5c2ebf1",
      "9f14b79892954ff6a983b13d25742d36",
      "ae557a2ecca247c59e660555acaea449",
      "4f1ec58b442f4a5eb0e9be67d5af9008",
      "60bd42463ebf4d709bb90800ec492259",
      "4b026350550741d9b4b6f64bf21c8d14"
     ]
    },
    "id": "LKzkUP1L42y5",
    "outputId": "392656b9-c943-470a-837f-fe5d0ce18e69"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a202b38f360949528369d2045dee1903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1763 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt_emb = model.encode(QA_txt, batch_size=32, normalize_embeddings=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PTTTrvUz-JfM"
   },
   "outputs": [],
   "source": [
    "in_memory=True\n",
    "client = Client()\n",
    "default_collection_settings= {\n",
    "\n",
    "    \"embedding_function\": embedding_functions.SentenceTransformerEmbeddingFunction(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iFVLygH2_fiT"
   },
   "outputs": [],
   "source": [
    "ids = [f\"q{i}\" for i in range(len(QA_txt))]\n",
    "metas = [{\"question\": example[\"question\"], \"answer\": example[\"answer\"]} for example in cleaned_dt]\n",
    "batch_size = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HnDKdNtM-iKZ"
   },
   "outputs": [],
   "source": [
    "documents = [f\"Q: {example['question']} A: {example['answer']}\" for example in cleaned_dt]\n",
    "collection = client.get_or_create_collection(name=\"quora_qa\")\n",
    "\n",
    "for i in range(0, len(ids), batch_size):\n",
    "    batch_ids = ids[i:i+batch_size]\n",
    "    batch_metas = metas[i:i+batch_size]\n",
    "    batch_docs = documents[i:i+batch_size]\n",
    "    batch_embs = txt_emb[i:i+batch_size]\n",
    "    collection.upsert(\n",
    "        ids=batch_ids,\n",
    "        documents=batch_docs,\n",
    "        embeddings=batch_embs,\n",
    "        metadatas=batch_metas\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRXSHtySCsVs",
    "outputId": "8154ad49-2c91-41b0-967c-715810bbcfc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=quora_qa)]\n"
     ]
    }
   ],
   "source": [
    "existing = client.list_collections()\n",
    "print(existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ilFxH1fkCxc-"
   },
   "outputs": [],
   "source": [
    "User_query = \"best persian restaurant?\"\n",
    "UQ_emb = model.encode(User_query)\n",
    "results = collection.query(\n",
    "    query_embeddings=UQ_emb,\n",
    "    n_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rB_1_u-GDljE",
    "outputId": "71192663-fefa-4ae1-d0b6-44382b6061c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is absolutely the best Indian restaurant in the world, and why?\n",
      "If you are seeking for a best Indian Restaurant in Bahrain. Your search is over with \"Al Wamiya Restaurant” Is the best Indian restaurant in all over the world Al Wasmiya Provide best Indian food Items and also they Provide Arabic dishes. Al Wasmiya World Famous for his tastiest Dam Pukth Biryani. For more information You can Visit Our Website\n"
     ]
    }
   ],
   "source": [
    "print(results[\"metadatas\"][0][0][\"question\"])\n",
    "print(results[\"metadatas\"][0][0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tjUjSUXDoIl",
    "outputId": "73dc9acd-7354-4451-e5b6-84d3f3e63831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to evaluate:\n",
    "dt_validation= cleaned_dt.shuffle(seed=42).select(range(1000))\n",
    "dt_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "_CVZNquWGADX"
   },
   "outputs": [],
   "source": [
    "test_queries = [example[\"question\"] for example in dt_validation]\n",
    "test_answers = [example[\"answer\"] for example in dt_validation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9AQTf-DGXSU",
    "outputId": "b257f9d7-fc63-47f2-f505-d9d7fb9af884"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@1: 0.053\n",
      "Precision@5: 0.238\n"
     ]
    }
   ],
   "source": [
    "K = 5\n",
    "\n",
    "correct_at_1 = 0\n",
    "correct_at_5 = 0\n",
    "\n",
    "for i, query in enumerate(test_queries):\n",
    "    UQ_emb = model.encode(query)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=UQ_emb,\n",
    "        n_results=K\n",
    "    )\n",
    "\n",
    "    retrieved_answers = [results[\"metadatas\"][0][j][\"answer\"] for j in range(K)]\n",
    "\n",
    "    ground_truth = test_answers[i]\n",
    "\n",
    "    if retrieved_answers[0] == ground_truth:\n",
    "        correct_at_1 += 1\n",
    "\n",
    "    if ground_truth in retrieved_answers:\n",
    "        correct_at_5 += 1\n",
    "\n",
    "total_queries = len(test_queries)\n",
    "precision_at_1 = correct_at_1 / total_queries\n",
    "precision_at_5 = correct_at_5 / total_queries\n",
    "\n",
    "print(f\"Precision@1: {precision_at_1:.3f}\")\n",
    "print(f\"Precision@5: {precision_at_5:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJzImd4yLyK8",
    "outputId": "86b73713-a354-4dba-a936-de1b5cc45ba4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1825630329.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
      "/tmp/ipython-input-1825630329.py:10: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# Not a great result but enough for the small model\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "collection_name = \"quora_qa\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "persist_directory = None\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316,
     "referenced_widgets": [
      "6d3e81b8cde24ae8a4ada3979d93b93d",
      "75911a7f452b4f8080aa8ad7a4a1e626",
      "7e6e9658efd045dab7bca5f50bec4131",
      "c444de079ff04a0884d492f2117eccdf",
      "0812258fb736479c89a48626fccd03c8",
      "44d3b21017364e4fb26397eb1bf93f90",
      "1e7c24d0065a4cd3b51d3b34a6eb616e",
      "49d5509053c648eda116d81b0aba6587",
      "bc3b960582b945f68ac75d0c0ca62f5c",
      "65570d19001447fdaa7abfeee41c301e",
      "994031075e4143fead6a1655a69eedd8",
      "59b01d0106ac4160898432438ef52c65",
      "b9850e510bfb43d2a78816db0eb2bd5c",
      "9965bd5fea3f409fbff34f38a05ef79f",
      "11e636a6015f43ae8fb32ca53da8c5df",
      "28a701c4f79f4f01ad10191399ebf2b0",
      "ed6d833903544537b107aade429aa26b",
      "9155a5446c544cd1834cf88aee0b9280",
      "477d75edeaf147eb9ab194d235091432",
      "1cdecce423ad46fb8283a863767e4469",
      "8f4220f7bf8d4c01910ecae18e339558",
      "3ca8c77f12064e9b96e3ca8d1a14e56e",
      "6b04bc18d91f4f2794ba9867db78e97b",
      "64259e609cd1419198145b378e2a9442",
      "1c1f0d0a29c24bfabe3a584c1485965f",
      "e0fe60a211aa409080c19508cd9156dd",
      "efeec703bb3c41a987ee7e46ffdba00c",
      "ac7c366fd6954017a2289138d0ad5d80",
      "1b0f6c75c094498a9986ffdf1706f0ce",
      "1a8d62904b0b42eca948b795a2b282dc",
      "f31274f47f70445b832a0dec0e15e7e1",
      "5138a24bc17f4136a1357932f0389137",
      "6a83ade6c0fc46c9a920f4834c87d0ab",
      "bdfc7a993770417cbc4998c9d0eff055",
      "d1b13d857a7c4d1290e16e2414e1b93e",
      "707444efcd164631bfa581c2e56e3d26",
      "6ce440d54255473f90b1a0e36583523a",
      "c04b3c039eac4b49b0bc390711ad15eb",
      "d0ce4c78905949729b76c6004bfd8659",
      "0bddcdfa4b4e4eca9b12a59873e3908c",
      "3e458f4c749045f19fccbfa1b9387968",
      "64f910090c154df1a106d2e23224a20c",
      "a992b7d00c4f4addadd05fb94c1a3b90",
      "8703d4675ae54de5bc05c00d444e1ab8",
      "83c104dfbdef4a22a6e3d08f7b5f472d",
      "8a64718316a8415187e3fd8ea7edc468",
      "2eb9ac097c844dceb41641c81ae2db19",
      "70d50de76cd049fea7c77efabce0be42",
      "ca4d3ef0c36b4d57ad829c4ec321465f",
      "549dad92a9a544c59dbae25f25810c5a",
      "1f6f7851ca504f918467e8b8a50b3033",
      "b414895fbbf44e2ca2006da188ff4e78",
      "e0e089d846ed42439883b6c7af5e7f8d",
      "375fd1b066374880b73ce7a290fa993a",
      "4fa4803e84fd4ff7b22dc15c486b0cf8",
      "4218b784df8b4dca8cdec3bbaca1cdf9",
      "825dda96b32c4751a1ff9375b5d7883f",
      "f8307eae17194eaeb44440aedaef44fa",
      "d8d6988b4a924b998f9cc07bb4ded944",
      "81ce396e4ed74fc2928083995c9b6d84",
      "4ba7480e11f24425a99f4e449d1e8256",
      "6dd5a54495ea4c46911283c542f561a4",
      "9c299a99e7f24a66a32e57259e35f307",
      "fa7a56b07d9c43a59453c3f2e7ceddb4",
      "d525e366d99e463bbc0025f9c2ba0af0",
      "7d7c4af2a4454ad6bfff1a2134b24a58",
      "39f08b0f4f3441108de88a8741776d41",
      "8b4d5e8068a345eba487948a1a66f19c",
      "95090030c74f41e7ab00259f218fd6c2",
      "fc81468f077e4f659c418f4281679fd3",
      "fef56f5c28b04439b4af0ccc601fb3cf",
      "7976a1772d564cccb46136e1f501d6da",
      "c1b5dca957064c6ea0de0a984316aa35",
      "395d26e86eba40c6a5317c8b529ad459",
      "ff2ef30fdb734009a15b2da3a1bf8597",
      "10514ed765f14f47ad1ae24853dc7dd7",
      "7ea629621ee34c50aa8156af4c2a3abc"
     ]
    },
    "id": "8mG1I9vjOnEi",
    "outputId": "64c70b49-caf7-4bd0-ced1-a47030a39af1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3e81b8cde24ae8a4ada3979d93b93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b01d0106ac4160898432438ef52c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b04bc18d91f4f2794ba9867db78e97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfc7a993770417cbc4998c9d0eff055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c104dfbdef4a22a6e3d08f7b5f472d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4218b784df8b4dca8cdec3bbaca1cdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f08b0f4f3441108de88a8741776d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipython-input-425032360.py:9: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
     ]
    }
   ],
   "source": [
    "llm_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "mNONfMygPNoV"
   },
   "outputs": [],
   "source": [
    "# the Retrieval QA chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LW_SYBapPPNW",
    "outputId": "9b36432e-0b96-47e9-9661-e7fb9c304485"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1383358897.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = rag_chain(user_question)\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated answer: Make fun projects in the various languages you are learning.\n",
      "\n",
      "--- Source #1 ---\n",
      "Q: I have a fairly basic understanding of Python. But now I want to learn C++. Does this require me to learn C first?\n",
      "A: Yes, because C++ is essentially the ++ addon to C. But you do not need to learn C to beautiful mastery. Stuff like union, pointer arithmetic, bitwise variables are of no use to modern computing anyway. C level overview understanding for syntax and skeletal awareness of how and what comprise a program is sufficient to go on to C++.\n",
      "\n",
      "--- Source #2 ---\n",
      "Q: I have a fairly basic understanding of Python. But now I want to learn C++. Does this require me to learn C first?\n",
      "A: You do not have to C first to learn C++. I would say your basic understanding of Python is better at understand to use C++ at a higher level then learning C.\n",
      "\n",
      "--- Source #3 ---\n",
      "Q: I have a fairly basic understanding of Python. But now I want to learn C++. Does this require me to learn C first?\n",
      "A: Not sure there IS a language that is easier to learn than Python. It’s a great first language, and it is ACTUALLY used in the real world, though in a different way than an enterprise-level, top-to-bottom, all purpose language like Java or C++. (Lookup how Data Analysts and AI researchers use Python over top of (to control) deeper C++ code libraries and tools.) If you already know C, then that and Python should be a good start for general programming, with Java and C++ as good followups. For web a development career track, HTML, JavaScript, CSS, and PHP may be better followups than Java and C++. Now “learning” a language is VERY DIFFERENT than actually using a language all-day, every day, for 3 years. Just knowing the syntax and how to form basic logical structures and objects is generally enough to “learn” a language. Subtleties of language quirks, variable assignments, memory management, and compiler tricks are deeper knowledge you gain by researching and using a language over a long period of time. Honestly, that’s not something to do “just in case” or to have that language “in your back pocket” ready for a hypothetical future employer. The reason to have that level of knowledge is because you ARE using the language and you WILL be using it in the future. That said, EXPERIMENT! Try making fun projects in the various languages you are learning. If there’s a language you already KNOW you will be using in your career, get started using it to make a Rock, Paper, Scissors, Lizard, Spock game. Or make a utility to sort and name pictures and internet saves in your collection. Scrape headlines off your favorite news website. By doing these things, and rewriting them again in other programming languages, you’ll get a good feel for how languages are similar and how they differ. But nothing replaces career-oriented institutional industrial-strength full-time work for really understanding a language inside and out.\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "user_question = \"What is the best way to learn Python as a beginner?\"\n",
    "result = rag_chain(user_question)\n",
    "print(\"Generated answer:\", result['result'])\n",
    "\n",
    "for i, doc in enumerate(result['source_documents']):\n",
    "    print(f\"\\n--- Source #{i+1} ---\")\n",
    "    print(\"Q:\", doc.metadata['question'])\n",
    "    print(\"A:\", doc.metadata['answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W3OmUmlYS861"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
